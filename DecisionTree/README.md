### 原理

#### 基本概念

- 决策树模型:从根节点开始一步一步走到叶子结点就是做决策的过程,最终所有的样本会落到叶子节点上,这样既能用来做分类也能用来做回归
- 决策树的组成
  - 根节点:第一个选择点,也可以理解为影响最大的那个决策
  - 非叶子结点与分支:中间过程,即是做完最大决策后面接着的一步一步细化的决策
  - 叶子节点:最终的决策结果

#### 特征切分(节点选择)

选择什么特征来进行数据切割做出决策,就需要一个衡量标准,最符合标准的那个特征就可以拿来做根节点,然后剩下的特征就可以依次用来做后续的切分

#### 衡量标准-熵

- 熵:表示随机变量不确定度的度量.即是物体内部的混乱程度.
- 表示公式:$H(X)=-\sum p_i*\log(p_i),i=1,2,\dots$

例子:样本$A=\{1,2,3,4\}$,样本$B=\{1,1,1,2,2\}$

那么$A$的熵等于

$$H(A)=-0.25*log_2(0.25)-0.25*log_2(0.25)-0.25*log_2(0.25)-0.25*log_2(0.25)=2$$

然后$B$的熵等于

$$H(B)=-0.4*log_2(0.4)-0.6*log_2(0.6)=0.97$$

可以看出来$A$的熵比$B$的熵更大,即$A$比$B$更加的混乱
