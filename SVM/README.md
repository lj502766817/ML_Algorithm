### 支持向量机原理

支持向量机(SVM)也是用来解决经典的二分问题的一种算法.SVM的目的就是找出能够一个能把样本二分类的面(在二维空间里就是一条线),并且使这两类样本点到这个面最近的的那个距离最大,通俗的说就是在两个样本最中间的那个面.那么SVM需要解决的问题就是找到那个面,假设这个面的方程为:
$$
W^TX+b=0
$$


那么问题就变成了到这个平面最近的样本点$X(x,y)$到这个平面的距离$h$最大.由于点到面的距离没那么好求,那么可以把这个距离做个转换.把这个距离转换成从平面上一点$X^\prime$到样本的一个向量$X-X^\prime$,在平面的单位法向量$e \over ||W||$上的投影.那么距离公式就变成了:
$$
distance(X,b,W)=|{e \over ||W||}(X-X^\prime)|
$$
并且有由前面的面方程可以将式子转换成:
$$
distance(X,b,W)={1 \over ||W||}|W^T{X}+b| \tag{决策方程}
$$


现在假设样本集是$(X_1,Y_1),(X_2,Y_2)\dots(X_n,Y_n)$,样本的类可以设成,当$X$为正例的时候$Y=1$,此时点到面的距离为正,当$X$为负例的时候$Y=-1$,此时点到面的距离为负数.并且设决策方程是$y(x)$.那么这样决策方程就有:
$$
\begin{cases}
y(x_i)>0 \Leftrightarrow y_i=1 \\
y(x_i)<0 \Leftrightarrow y_i=-1
\end{cases}
\Rightarrow y_iy(x_i)>0
$$
那么由于y的绝对值是1,并且将维度扩展到高维度的时候可以用核函数$\phi$进行转换,那么整体的距离公式最后就变成:
$$
distance={{y_i\cdot(w^T \cdot \phi(x_i)+b)} \over ||w||}
$$


